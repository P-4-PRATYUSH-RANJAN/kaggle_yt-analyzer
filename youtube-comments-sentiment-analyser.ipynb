{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-05-28T04:09:17.616166Z","iopub.execute_input":"2023-05-28T04:09:17.616547Z","iopub.status.idle":"2023-05-28T04:09:17.650911Z","shell.execute_reply.started":"2023-05-28T04:09:17.616473Z","shell.execute_reply":"2023-05-28T04:09:17.649962Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"/kaggle/input/blackadam-trailer-comments/comments.csv\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Dataextraction","metadata":{}},{"cell_type":"code","source":"# from youtube_comment_scraper_python import *\n# import pandas as pd\n\n# link = input(\"Youtube links: \")\n# saved = input(\"Output name: \")\n# youtube.open(link)\n\n# response = youtube.video_comments()\n# all_data = []\n# for i in range(0, 20): # It will scroll 10 times\n#     response = youtube.video_comments()\n#     data = response['body']\n#     all_data.extend(data)\n# df = pd.DataFrame(data)\n# df.to_csv(saved)","metadata":{"execution":{"iopub.status.busy":"2023-05-28T04:09:17.652235Z","iopub.execute_input":"2023-05-28T04:09:17.652522Z","iopub.status.idle":"2023-05-28T04:09:17.657098Z","shell.execute_reply.started":"2023-05-28T04:09:17.652496Z","shell.execute_reply":"2023-05-28T04:09:17.656075Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":"# Datatransformation","metadata":{}},{"cell_type":"markdown","source":"* **Libraries required**","metadata":{}},{"cell_type":"code","source":"#Libraries \nimport numpy as np\nimport pandas as pd \nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport os\n\n# Import functions for data preprocessing & data preparation\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.utils import resample\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom nltk.sentiment.vader import SentimentIntensityAnalyzer\n\nfrom nltk.tokenize import word_tokenize\nfrom nltk.stem import WordNetLemmatizer\nfrom nltk.stem import PorterStemmer, LancasterStemmer\nfrom nltk.stem.snowball import SnowballStemmer\nfrom nltk.corpus import stopwords\nfrom nltk.corpus import wordnet\nimport string\nfrom string import punctuation\nimport nltk\nimport re","metadata":{"execution":{"iopub.status.busy":"2023-05-28T04:09:17.675851Z","iopub.execute_input":"2023-05-28T04:09:17.676182Z","iopub.status.idle":"2023-05-28T04:09:19.261972Z","shell.execute_reply.started":"2023-05-28T04:09:17.676155Z","shell.execute_reply":"2023-05-28T04:09:19.260980Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":"* **Read data**","metadata":{}},{"cell_type":"code","source":"data = pd.read_csv('../input/blackadam-trailer-comments/comments.csv')\ndata.columns\ndata1=data.drop(['Unnamed: 0','Likes','Time','user','UserLink'],axis=1)\ndata1","metadata":{"execution":{"iopub.status.busy":"2023-05-28T04:09:19.263787Z","iopub.execute_input":"2023-05-28T04:09:19.264090Z","iopub.status.idle":"2023-05-28T04:09:19.300940Z","shell.execute_reply.started":"2023-05-28T04:09:19.264066Z","shell.execute_reply":"2023-05-28T04:09:19.299774Z"},"trusted":true},"execution_count":4,"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"                                               Comment\n0    Love how Dr. Fate's design looks and how cool ...\n1    I can’t get over how good everything looks. Dr...\n2    Really hoping that this can save DC's movie un...\n3    U cant deny how good this looks.Now if they ca...\n4    From this trailer, I have a feeling that this ...\n..                                                 ...\n275  I want to see this. It may be one of his most ...\n276       wow thats very amazing. I can't wait to see.\n277                    Doctor Fate is why i'm watching\n278  This looks fire. DC looks like they stepping t...\n279  Shazam : \"I don't want fight you Black Adam.\"B...\n\n[280 rows x 1 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Comment</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Love how Dr. Fate's design looks and how cool ...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>I can’t get over how good everything looks. Dr...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Really hoping that this can save DC's movie un...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>U cant deny how good this looks.Now if they ca...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>From this trailer, I have a feeling that this ...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>275</th>\n      <td>I want to see this. It may be one of his most ...</td>\n    </tr>\n    <tr>\n      <th>276</th>\n      <td>wow thats very amazing. I can't wait to see.</td>\n    </tr>\n    <tr>\n      <th>277</th>\n      <td>Doctor Fate is why i'm watching</td>\n    </tr>\n    <tr>\n      <th>278</th>\n      <td>This looks fire. DC looks like they stepping t...</td>\n    </tr>\n    <tr>\n      <th>279</th>\n      <td>Shazam : \"I don't want fight you Black Adam.\"B...</td>\n    </tr>\n  </tbody>\n</table>\n<p>280 rows × 1 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"* **Data labelling**","metadata":{}},{"cell_type":"code","source":"nltk.download('vader_lexicon')\nsentiments = SentimentIntensityAnalyzer()\ndata1[\"Positive\"] = [sentiments.polarity_scores(i)[\"pos\"] for i in data1[\"Comment\"]]\ndata1[\"Negative\"] = [sentiments.polarity_scores(i)[\"neg\"] for i in data1[\"Comment\"]]\ndata1[\"Neutral\"] = [sentiments.polarity_scores(i)[\"neu\"] for i in data1[\"Comment\"]]\ndata1['Compound'] = [sentiments.polarity_scores(i)[\"compound\"] for i in data1[\"Comment\"]]\nscore = data1[\"Compound\"].values\nsentiment = []\nfor i in score:\n    if i >= 0.05 :\n        sentiment.append('Positive')\n    elif i <= -0.05 :\n        sentiment.append('Negative')\n    else:\n        sentiment.append('Neutral')\ndata1[\"Sentiment\"] = sentiment\ndata1.head()","metadata":{"execution":{"iopub.status.busy":"2023-05-28T04:09:19.302381Z","iopub.execute_input":"2023-05-28T04:09:19.302852Z","iopub.status.idle":"2023-05-28T04:09:19.708080Z","shell.execute_reply.started":"2023-05-28T04:09:19.302816Z","shell.execute_reply":"2023-05-28T04:09:19.706760Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stderr","text":"[nltk_data] Downloading package vader_lexicon to\n[nltk_data]     /usr/share/nltk_data...\n[nltk_data]   Package vader_lexicon is already up-to-date!\n","output_type":"stream"},{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"                                             Comment  Positive  Negative  \\\n0  Love how Dr. Fate's design looks and how cool ...     0.384     0.000   \n1  I can’t get over how good everything looks. Dr...     0.153     0.000   \n2  Really hoping that this can save DC's movie un...     0.375     0.000   \n3  U cant deny how good this looks.Now if they ca...     0.302     0.049   \n4  From this trailer, I have a feeling that this ...     0.131     0.000   \n\n   Neutral  Compound Sentiment  \n0    0.616    0.8910  Positive  \n1    0.847    0.6801  Positive  \n2    0.625    0.9216  Positive  \n3    0.649    0.9262  Positive  \n4    0.869    0.4416  Positive  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Comment</th>\n      <th>Positive</th>\n      <th>Negative</th>\n      <th>Neutral</th>\n      <th>Compound</th>\n      <th>Sentiment</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Love how Dr. Fate's design looks and how cool ...</td>\n      <td>0.384</td>\n      <td>0.000</td>\n      <td>0.616</td>\n      <td>0.8910</td>\n      <td>Positive</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>I can’t get over how good everything looks. Dr...</td>\n      <td>0.153</td>\n      <td>0.000</td>\n      <td>0.847</td>\n      <td>0.6801</td>\n      <td>Positive</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Really hoping that this can save DC's movie un...</td>\n      <td>0.375</td>\n      <td>0.000</td>\n      <td>0.625</td>\n      <td>0.9216</td>\n      <td>Positive</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>U cant deny how good this looks.Now if they ca...</td>\n      <td>0.302</td>\n      <td>0.049</td>\n      <td>0.649</td>\n      <td>0.9262</td>\n      <td>Positive</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>From this trailer, I have a feeling that this ...</td>\n      <td>0.131</td>\n      <td>0.000</td>\n      <td>0.869</td>\n      <td>0.4416</td>\n      <td>Positive</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"* **Final data**","metadata":{}},{"cell_type":"code","source":"data2=data1.drop(['Positive','Negative','Neutral','Compound'],axis=1)\ndata2.head()","metadata":{"execution":{"iopub.status.busy":"2023-05-28T04:09:19.710137Z","iopub.execute_input":"2023-05-28T04:09:19.710465Z","iopub.status.idle":"2023-05-28T04:09:19.726880Z","shell.execute_reply.started":"2023-05-28T04:09:19.710427Z","shell.execute_reply":"2023-05-28T04:09:19.725382Z"},"trusted":true},"execution_count":6,"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"                                             Comment Sentiment\n0  Love how Dr. Fate's design looks and how cool ...  Positive\n1  I can’t get over how good everything looks. Dr...  Positive\n2  Really hoping that this can save DC's movie un...  Positive\n3  U cant deny how good this looks.Now if they ca...  Positive\n4  From this trailer, I have a feeling that this ...  Positive","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Comment</th>\n      <th>Sentiment</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Love how Dr. Fate's design looks and how cool ...</td>\n      <td>Positive</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>I can’t get over how good everything looks. Dr...</td>\n      <td>Positive</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Really hoping that this can save DC's movie un...</td>\n      <td>Positive</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>U cant deny how good this looks.Now if they ca...</td>\n      <td>Positive</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>From this trailer, I have a feeling that this ...</td>\n      <td>Positive</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"* **Data transformation**","metadata":{}},{"cell_type":"code","source":"stop_words = stopwords.words('english')\nporter_stemmer = PorterStemmer()\nlancaster_stemmer = LancasterStemmer() \nsnowball_stemer = SnowballStemmer(language=\"english\")\nlzr = WordNetLemmatizer()","metadata":{"execution":{"iopub.status.busy":"2023-05-28T04:09:19.728543Z","iopub.execute_input":"2023-05-28T04:09:19.729045Z","iopub.status.idle":"2023-05-28T04:09:19.741222Z","shell.execute_reply.started":"2023-05-28T04:09:19.729002Z","shell.execute_reply":"2023-05-28T04:09:19.740203Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"def text_processing(text):   \n    # convert text into lowercase\n    text = text.lower()\n\n    # remove new line characters in text\n    text = re.sub(r'\\n',' ', text)\n    \n    # remove punctuations from text\n    text = re.sub('[%s]' % re.escape(punctuation), \"\", text)\n    \n    # remove references and hashtags from text\n    text = re.sub(\"^a-zA-Z0-9$,.\", \"\", text)\n    \n    # remove multiple spaces from text\n    text = re.sub(r'\\s+', ' ', text, flags=re.I)\n    \n    # remove special characters from text\n    text = re.sub(r'\\W', ' ', text)\n\n    text = ' '.join([word for word in word_tokenize(text) if word not in stop_words])\n    \n    # stemming using porter stemmer from nltk package - msh a7sn 7aga - momken: lancaster, snowball\n    # text=' '.join([porter_stemmer.stem(word) for word in word_tokenize(text)])\n    # text=' '.join([lancaster_stemmer.stem(word) for word in word_tokenize(text)])\n    # text=' '.join([snowball_stemer.stem(word) for word in word_tokenize(text)])\n    \n    # lemmatizer using WordNetLemmatizer from nltk package\n    text=' '.join([lzr.lemmatize(word) for word in word_tokenize(text)])\n\n    return text","metadata":{"execution":{"iopub.status.busy":"2023-05-28T04:09:19.743187Z","iopub.execute_input":"2023-05-28T04:09:19.744098Z","iopub.status.idle":"2023-05-28T04:09:19.753016Z","shell.execute_reply.started":"2023-05-28T04:09:19.744063Z","shell.execute_reply":"2023-05-28T04:09:19.751938Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"nltk.download('omw-1.4')\ndata_copy = data2.copy()\ndata_copy.Comment = data_copy.Comment.apply(lambda text: text_processing(text))","metadata":{"execution":{"iopub.status.busy":"2023-05-28T04:09:19.754850Z","iopub.execute_input":"2023-05-28T04:09:19.755562Z","iopub.status.idle":"2023-05-28T04:09:21.830631Z","shell.execute_reply.started":"2023-05-28T04:09:19.755528Z","shell.execute_reply":"2023-05-28T04:09:21.829652Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stderr","text":"[nltk_data] Downloading package omw-1.4 to /usr/share/nltk_data...\n","output_type":"stream"}]},{"cell_type":"code","source":"le = LabelEncoder()\ndata_copy['Sentiment'] = le.fit_transform(data_copy['Sentiment'])","metadata":{"execution":{"iopub.status.busy":"2023-05-28T04:09:21.832662Z","iopub.execute_input":"2023-05-28T04:09:21.833202Z","iopub.status.idle":"2023-05-28T04:09:21.838457Z","shell.execute_reply.started":"2023-05-28T04:09:21.833169Z","shell.execute_reply":"2023-05-28T04:09:21.837838Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"processed_data = {\n    'Sentence':data_copy.Comment,\n    'Sentiment':data_copy['Sentiment']\n}\n\nprocessed_data = pd.DataFrame(processed_data)\nprocessed_data.head()","metadata":{"execution":{"iopub.status.busy":"2023-05-28T04:09:21.839731Z","iopub.execute_input":"2023-05-28T04:09:21.840252Z","iopub.status.idle":"2023-05-28T04:09:21.860121Z","shell.execute_reply.started":"2023-05-28T04:09:21.840221Z","shell.execute_reply":"2023-05-28T04:09:21.858335Z"},"trusted":true},"execution_count":11,"outputs":[{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"                                            Sentence  Sentiment\n0  love dr fate design look cool scene look power...          2\n1  get good everything look dr fate magic cyclone...          2\n2  really hoping save dc movie universe looking n...          2\n3  u cant deny good looksnow follow rest movie go...          2\n4  trailer feeling movie going one movie would ne...          2","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Sentence</th>\n      <th>Sentiment</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>love dr fate design look cool scene look power...</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>get good everything look dr fate magic cyclone...</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>really hoping save dc movie universe looking n...</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>u cant deny good looksnow follow rest movie go...</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>trailer feeling movie going one movie would ne...</td>\n      <td>2</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"processed_data['Sentiment'].value_counts()","metadata":{"execution":{"iopub.status.busy":"2023-05-28T04:09:21.864209Z","iopub.execute_input":"2023-05-28T04:09:21.865012Z","iopub.status.idle":"2023-05-28T04:09:21.876563Z","shell.execute_reply.started":"2023-05-28T04:09:21.864977Z","shell.execute_reply":"2023-05-28T04:09:21.875723Z"},"trusted":true},"execution_count":12,"outputs":[{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"2    205\n1     39\n0     36\nName: Sentiment, dtype: int64"},"metadata":{}}]},{"cell_type":"markdown","source":"* **Balancing data**","metadata":{}},{"cell_type":"code","source":"df_neutral = processed_data[(processed_data['Sentiment']==1)] \ndf_negative = processed_data[(processed_data['Sentiment']==0)]\ndf_positive = processed_data[(processed_data['Sentiment']==2)]\n\n# upsample minority classes\ndf_negative_upsampled = resample(df_negative, \n                                 replace=True,    \n                                 n_samples= 205, \n                                 random_state=42)  \n\ndf_neutral_upsampled = resample(df_neutral, \n                                 replace=True,    \n                                 n_samples= 205, \n                                 random_state=42)  \n\n\n# Concatenate the upsampled dataframes with the neutral dataframe\nfinal_data = pd.concat([df_negative_upsampled,df_neutral_upsampled,df_positive])","metadata":{"execution":{"iopub.status.busy":"2023-05-28T04:09:21.877906Z","iopub.execute_input":"2023-05-28T04:09:21.878155Z","iopub.status.idle":"2023-05-28T04:09:21.900616Z","shell.execute_reply.started":"2023-05-28T04:09:21.878132Z","shell.execute_reply":"2023-05-28T04:09:21.899775Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"final_data['Sentiment'].value_counts()","metadata":{"execution":{"iopub.status.busy":"2023-05-28T04:09:21.901672Z","iopub.execute_input":"2023-05-28T04:09:21.902071Z","iopub.status.idle":"2023-05-28T04:09:21.920489Z","shell.execute_reply.started":"2023-05-28T04:09:21.902047Z","shell.execute_reply":"2023-05-28T04:09:21.919357Z"},"trusted":true},"execution_count":14,"outputs":[{"execution_count":14,"output_type":"execute_result","data":{"text/plain":"0    205\n1    205\n2    205\nName: Sentiment, dtype: int64"},"metadata":{}}]},{"cell_type":"code","source":"corpus = []\nfor sentence in final_data['Sentence']:\n    corpus.append(sentence)\ncorpus[0:5]","metadata":{"execution":{"iopub.status.busy":"2023-05-28T04:09:21.922236Z","iopub.execute_input":"2023-05-28T04:09:21.922652Z","iopub.status.idle":"2023-05-28T04:09:21.933437Z","shell.execute_reply.started":"2023-05-28T04:09:21.922616Z","shell.execute_reply":"2023-05-28T04:09:21.932228Z"},"trusted":true},"execution_count":15,"outputs":[{"execution_count":15,"output_type":"execute_result","data":{"text/plain":"['trailer look sick im definitely watching movie',\n 'actually look like villain trailer',\n 'movie going push dc top comic book movie disaster early dceu new msheu mess two awesome projekts behind suicide squad peacemaker yeah going rock pun kinda intended',\n 'damn sure im gon na watchdc seems going right track',\n 'okay look absolutely incredible dc making look foolish ever even skeptical film definitely seeing opening weekend']"},"metadata":{}}]},{"cell_type":"code","source":"from sklearn.feature_extraction.text import CountVectorizer\ncv = CountVectorizer(max_features=1500)\nX = cv.fit_transform(corpus).toarray()\ny = final_data.iloc[:, -1].values","metadata":{"execution":{"iopub.status.busy":"2023-05-28T04:09:21.934712Z","iopub.execute_input":"2023-05-28T04:09:21.935048Z","iopub.status.idle":"2023-05-28T04:09:21.968860Z","shell.execute_reply.started":"2023-05-28T04:09:21.935016Z","shell.execute_reply":"2023-05-28T04:09:21.967690Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"markdown","source":"* **Machine learning model**","metadata":{}},{"cell_type":"code","source":"from sklearn.naive_bayes import GaussianNB\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)\nclassifier = GaussianNB()\nclassifier.fit(X_train, y_train)","metadata":{"execution":{"iopub.status.busy":"2023-05-28T04:09:21.970021Z","iopub.execute_input":"2023-05-28T04:09:21.970978Z","iopub.status.idle":"2023-05-28T04:09:21.988819Z","shell.execute_reply.started":"2023-05-28T04:09:21.970944Z","shell.execute_reply":"2023-05-28T04:09:21.988152Z"},"trusted":true},"execution_count":17,"outputs":[{"execution_count":17,"output_type":"execute_result","data":{"text/plain":"GaussianNB()"},"metadata":{}}]},{"cell_type":"markdown","source":"* **Evaluation**","metadata":{}},{"cell_type":"code","source":"from sklearn.metrics import confusion_matrix, accuracy_score\ny_pred = classifier.predict(X_test)\ncm = confusion_matrix(y_test, y_pred)\ncm","metadata":{"execution":{"iopub.status.busy":"2023-05-28T04:09:21.989752Z","iopub.execute_input":"2023-05-28T04:09:21.990446Z","iopub.status.idle":"2023-05-28T04:09:22.003308Z","shell.execute_reply.started":"2023-05-28T04:09:21.990419Z","shell.execute_reply":"2023-05-28T04:09:22.002656Z"},"trusted":true},"execution_count":18,"outputs":[{"execution_count":18,"output_type":"execute_result","data":{"text/plain":"array([[58,  0,  0],\n       [ 0, 70,  0],\n       [11,  1, 45]])"},"metadata":{}}]},{"cell_type":"code","source":"nb_score = accuracy_score(y_test, y_pred)\nprint('accuracy',nb_score)","metadata":{"execution":{"iopub.status.busy":"2023-05-28T04:09:22.004196Z","iopub.execute_input":"2023-05-28T04:09:22.005038Z","iopub.status.idle":"2023-05-28T04:09:22.010276Z","shell.execute_reply.started":"2023-05-28T04:09:22.005007Z","shell.execute_reply":"2023-05-28T04:09:22.009500Z"},"trusted":true},"execution_count":19,"outputs":[{"name":"stdout","text":"accuracy 0.9351351351351351\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Hope you like my notebooks,Your comments will add value to the notebook,Please comment down the improvements!! and upvote if you liked it.**","metadata":{}}]}